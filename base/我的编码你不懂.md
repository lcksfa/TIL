# 编码到底是个啥

> 这里的编码不是指编写代码，而是字符的编码方式；

先提出几个问题：
1. utf8和 unincode是一回事么？
2. ANSI编码和 ASCII码是什么
3. 宽字节 和窄字节又是什么
4. 国标码和utf8 有什么不同？
5. wchar_t和char

首先 明确一点，计算机只认识0和1，所以计算机不管是存还是读取都是基于0和1的序列；
而把这些0和1组成的序列组织起来变成人类可读的文字就是__编码标准__需要完成的工作了。

打开sublime的encoding列表，我们可以看到编码标准是真的多，每个地区和国家似乎都想把0和1的序列定义一下然后组成自己国家的文字，可以，这带来了很大的麻烦。特别是在全球互联的背景下。因为A国的01序列组成的A国标准的文字编码到了B国会按B国的文字编码重新解读，于是在B国人们的解读下，就是一团乱码，形成了`我的编码你不懂`的状况。

## Unicode
于是Unicode出来了，被称为世界级的标准字符集，里面拟定了所有国家所有地区的文字的全集。不论英语、中文、俄语还是什么不知名的语种，unicode无所不包。那么你可能会问，字符集又是什么呢？还是回到计算机的原理说起，计算机只认识0和1 ，人们自然也只能使用0和1组成的序列来组成字符集了，于是在unicode里，比如说41标示A。可以这么说，人们把数字从0往后数，每个数字都标示一个字。因为英语的特殊地位，它自然在数数的最前头。

所以，__我认为所谓字符集就是定义了数字和字的映射关系__；不够unicode做的大，把世界上所有的文字都映射进去了；

## UTF-8 和UTF-16
UTF 是 A Unicode transformation format 的简写；

使用Unicode的数字和字的映射关系的编码方式 主要是UTF-8 和UTF-16；
现在回头看看UTF-8，现在我们就需要把这些数在计算机里表示出来了，可以说UTF-8是最折中的表示方案，它先使用8位bit表示一个数字，比如1，2，3的表示方式为`0000 0001` `0000 0010` ` 0000 0011`,值得注意的是，这里的1 2 3并不是真实的我们语言世界里的 1 2 3 ，而需要查询[Unicode映射表](https://unicode-table.com/en/#0001)后知道数字1 对应的值 为 SOH ,2 对应STX ，3对应ETX；

不过，我们知道，8位的2进制数最大只能到255，大于255的数字怎么表示呢？再往8位里面加8位序列，扩容，也就是变成了16位表示一个更大的数；事实上utf-8编码 到了007F 后即开始使用16位表示更大的数了；
而更大的数字则使用更多的数位表示，目前最大到了32位；具体的编码方式 [参看这里](https://naveenr.net/unicode-character-set-and-utf-8-utf-16-utf-32-encoding/)

UTF-16 同UTF-8 理解一样，使用16位表示最初的数字，UTF-16编码是一种可变字节编码方案，它使用2个字节或4个字节来表示unicode代码点。 所有现代语言的大多数字符都使用2个字节表示。如 1 的表示为 `00000000 0000 0001`仍然表示Unicode里的SOH。不能把UTF-16理解为一个16位的编码方式；

同理的：UTF-32 编码是固定字节编码方案，它使用4个字节来表示所有代码点。

现在我们来回答 第一个问题：
unicode 是一个字符集标准，它规定了数字和具体的字之间的映射关系；
而UTF-家族是unicode里的数字（代码点）的编码实现方式；

## ANSI编码
American National Standards Institute （美国国家标准协会）

ANSI编码是一个稍微通用的术语，用于指代系统上的标准代码页，通常是Windows。 在西方/美国，它被更恰当地称为Windows-1252.系统。 （它可以代表其他系统上的某些其他Windows代码页。）这实际上是ASCII字符集的扩展，因为它包含所有带有128个字符代码的ASCII字符。 这种差异是由于“ANSI”编码是8位而不是7位，因为ASCII是（ASCII现在几乎总是编码为8位字节，MSB设置为0）。 名称“ANSI”用词不当，因为它不符合任何实际的ANSI标准，但名称已卡住。 ANSI与UTF-8不同。

严格来说，没有ANSI编码这样的东西。 通俗地，术语ANSI用于几种不同的编码：`ISO 8859-1`` Windows CP1252` Windows机器上的当前系统编码（在Win32 API术语中）。

维基百科的定义：
`
ANSI character set
From Wikipedia, the free encyclopedia
Jump to navigationJump to search
The phrase ANSI character set has no well-defined meaning and has been used to refer to the following, among other things:

Windows code pages, a collection of 8-bit character sets compatible with ASCII but incompatible with each other, especially those code pages that are partly compatible with ISO-8859, most commonly Windows Latin 1
Windows-1252 is referred to as "ANSI" especially often.
Code page 437, the character set of the original IBM PC (especially in the context of ANSI art which is used as graphics especially in BBS and made as demoscene products.)
ASCII, a 7-bit character set. (Very rarely.)
ANSEL, the American National Standard for Extended Latin Alphabet Coded Character Set. (Very rarely.)
ISO-8859, a collection of 8-bit character sets compatible with ASCII. (Very rarely.)

ANSI字符集没有明确定义的含义，并且用于指代以下内容：
Windows代码页，
8位字符的集合 与ASCII兼容但彼此不兼容的集合，
尤其是那些与ISO-8859部分兼容的代码页，最常见的是Windows Latin 1 
Windows-1252特别经常被称为“ANSI”。 代码页437，
原始IBM PC的字符集（特别是在ANSI艺术的上下文中，特别是在BBS中用作图形并作为demoscene产品。）
ASCII，一个7位字符集。 （非常罕见。）
ANSEL，扩展拉丁字母编码字符集的美国国家标准。 （非常罕见。）
ISO-8859，与ASCII兼容的8位字符集的集合。 （非常稀有。）
`

## ASCII码
ASCII只定义了一个带有128个符号的7位代码页

回答第二个问题，在windows系统中，使用ANSI编码概念完全是个误会，是指代windows的代码页，所以我们经常使用不同的代码页转换来却换字符编码，而ascii是一个只包含少量符号和英文的字符集，由7位bit表示；


## 宽字节 和窄字节
在win32开发中一个项目的字符集一般分为Unicode字符集和多字节字符集，一般我们会选择Unicode字符集，因为这样很方便我们开发，值得一提的是，Unicode字符集也许我们很熟悉，平时所说的宽字节就是Unicode，多字节就是指的ANSI，GB等。

这些从ANSI标准派生的字符集被习惯的统称为ANSI字符集，这样的字符集有很多，我们常见的GB-2312就是其中之一。它们正式的名称应该是MBCS(Multi-Byte Chactacter System，即多字节字符系统)。这些派生字符集的特点是以ASCII 127 bits为基础，兼容ASCII 127，他们使用大于128的编码作为一个Leading Byte，紧跟在Leading Byte后的第二（甚至第三）个字符与Leading Byte一起作为实际的编码。 

所以，可知，我们常说的宽字节 实际就是指的使用unicode编码方式
而窄字节 是MBCS系列的编码方式；

### char
我们使用char表示一个窄字节符号；那么问题来了，当我们使用char存储中文时，发生了什么呢？
看下代码就明白了

```c++
#include <iostream>
#include <cstring>
int main(int argc, char const *argv[]) {

    char chinese[] = "中文";
    std::cout << "size of 中文 is:" << sizeof(chinese) << std::endl;
    std::cout << "length of 中文 is:" << strlen(chinese) << std::endl;

    char english[] = "eg";
    std::cout << "size of eg is:" << sizeof(english) << std::endl;
    std::cout << "length of eg is:" << strlen(english) << std::endl;

    wchar_t Lchinese[] = L"中文";
    std::wcout << "size of L中文 is:" << sizeof(Lchinese) << std::endl;
    std::wcout << "length of L中文 is:" << wcslen(Lchinese) << std::endl;
    wchar_t Lenglish[] = L"eg";
    std::wcout << "size of Leg is:" << sizeof(Lenglish) << std::endl;
    std::wcout << "length of Leg is:" << wcslen(Lenglish) << std::endl;
    return 0;
}
```
输出结果
```c++
size of 中文 is:7
length of 中文 is:6
size of eg is:3
length of eg is:2
size of L is:12
length of L is:2
size of Leg is:12
length of Leg is:2
[Finished in 1.0s]
```
这段程序是在linux系统的输出结果，暂时没有windows的环境；
先说说char，在linux下，一个char是1个字节，我的编程文件是utf-8格式的，所以每个中文都是使用utf-8存储，我们查看“中的”utf-8编码是`0xE4 0xB8 0xAD`,而“文”的是`0xE6 0x96 0x87`。可见“中文”二字需要6个字节 来安放自己，加上`\0`，一共7个字节。
而计算length时，是按char来分割计算的，一个6个char。

英文就好理解了，e和g各占一个char，不需要 多余的解释了。

当使用whar_t时，linux系统使用UTF-32来表示，即每个字符都是4位字节的，“中”的UTF-32的编码为`0x00004E2D`， “文”为`0x00006587` ，所以二者一共8个字节，另外需要注意的是结束符也是占用4个字节的，所以它们一起需要的字节数就是12了。
不过，在length上，还是2个wchar_t。

由此，我们得出的结论是，char和wchar_t都可以存储中文；而当我们使用char存储中文时，是比wchar_t使用的空间要小的，但是我们在计算字符串长度时是不准确的。所以，这里，我认为，当我们需要使用一段非西文字符串具体长度的时候，一定要使用wchar_t来存储，这其实是一个粒度问题。

### wchar_t 

在实际开发中，我们使用wchar_t表示一个宽字节符号：
While a char takes up a single byte, a **wchar_t** takes up 4 bytes on **Linux** in contrast to the 2 bytes that **wchar_t** takes up in **Windows** NT. 

在linux里，一个宽字节wchar_t 占用4个字节，而在windows里占用2个字节，二者说到底是使用的unicode的编码方式不同，llnux里使用UTF-32 ，而windows里使用UTF-16。

继续上面的例子，之前的代码文件的编码是utf-8的，那么如果我把它改为gb2312呢，会发生什么？

在我的linux系统下，无法编译通过，因为linux系统无法解读gb2312编码，所以无法通过；
还是看看windows系统吧，在中文操作系统下，VS的默认编码就是gb2312的。
运行结果为
```c++
size of 中文 is:5
length of 中文 is:4
size of eg is:3
length of eg is:2
size of L中文 is:6
length of L中文 is:2
size of Leg is:6
length of Leg is:2
```
先说char时的，**中**的GB2312 编码为`D6D0`,占用两个字节 ；**文**的为`CEC4`。二者一共4个字节，加一个结束符，共5个字节的size；而length是4个char；使用的[在线查询工具](https://www.qqxiuzi.cn/bianma/zifuji.php)

在wchar_t时，windows使用UTF-16编码，**中**为`\4e\2d` ，**文**为`\65\87`，二者一共4个字节。
再加2个字节的结束符，一共6个字节的size；而length是2个wchar_t。

由此可见，使用不同的编码方式，对编程的影响是巨大的，而只有统一了字符的类型，才能跨平台使用，而不至于因编码问题把代码改来改去。

## GB2312
简体中文的国标码，不过后者是包括了前者的。在windows下编程，一定会和这个编码方式打交道。

之后 ，有发展出了GBK ，后续的扩大集合为GB18030。 	

具体的[参看这里](https://www.zhihu.com/question/19677619)

可以简单的区分为 GB 2312 过时标准、GBK 微软标准、GB 18030 国家标准三个标准
一般情况用 GB18030即可，方正都是向下兼容的.


## 字符编码的转换

### 为什么要转

我们先看看如下代码的输出

```c++
#include <iostream>
#include <cstring>

int main(int argc, char const *argv[]) {
    char chinese[] = "中文";
    unsigned int c1 = chinese[0];
    std::cout << "chinese char1 0x" << std::hex << c1 << "\n";

    wchar_t Lchinese[] = L"中文";
    unsigned int c2 = Lchinese[0];
    std::cout << "Lchinese char1 0x" << std::hex << c2 << "\n";
    return 0;
}
```

Linux下：

```
chinese char1 0xffffffe4
Lchinese char1 0x4e2d
```

windows下

```
chinese char1 0xffffffd6
Lchinese char1 0x4e2d
```

解释：

Linux下使用的utf-8文件编码，编译期并不识别gb2312，所以第一个字符char中存储的是汉字`中`的第一个UTF8编码，入前所述为e4

windows下使用的是国标码，GB2312，汉字中的第一个GB码数字为D6 ,符合查询结果。

两个系统上，使用L封装的字符，在内存中二进制形式是一样的，都是`4e2d`，



可见，在两种编码的文件下，文字本身虽然`中文`两字，但是实际的存储方式其实是不同的。那么反向思考下，对于存储的二进制的磁盘而言，我们需要招对合适的解码方式才能正常显示汉字，否则，将出现乱码，乱码的根本原因就是把本属于编码标准的二进制序列使用了其他的编码方式去映射。如果乱码后要显示成可识别的字，那么就需要编码转换了，不过弄明白了乱码的本质，要使得回复本来面目也就清楚了，即让**错误的编码映射解读为正确的映射关系**即可。



目前Windows的内核已经采用Unicode编码，这样在内核上可以支持全世界所有的语言文字 。但是由于现有的大量程序和文档都采用了某种特定语言的编码，例如GBK，Windows不可 能不支持现有的编码，而全部改用Unicode。
Windows使用代码页(code page)来适应各个国家和地区。code page可以被理解为前面提到 的内码。GBK对应的code page是CP936。
微软也为GB18030定义了code page：CP54936。但是由于GB18030有一部分4字节编码，而Windows的代码页只支持单字节和双字节编码，所以这个code page是无法真正使用的。



所谓代码页(code page)就是针对一种语言文字的字符编码。

例如GBK的code page是CP936 ，

BIG5的code page是CP950，

GB2312的code page是CP20936。

Windows中有缺省代码页的概念，即缺省用什么编码来解释字符。例如Windows的记事本打 开了一个文本文件，里面的内容是字节流：BA、BA、D7、D6。Windows应该去怎么解释它呢 ？
是按照Unicode编码解释、还是按照GBK解释、还是按照BIG5解释，还是按照ISO8859-1去解 释？如果按GBK去解释，就会得到“汉字”两个字。按照其它编码解释，可能找不到对应的 字符，也可能找到错误的字符。所谓“错误”是指与文本作者的本意不符，这时就产生了 乱码。
答案是Windows按照当前的**缺省代码页**去解释文本文件里的字节流。缺省代码页可以通过控 制面板的区域选项设置。记事本的另存为中**有一项ANSI，其实就是按照缺省代码页的编码 方法保存**。

Windows的内码是Unicode，它在技术上可以同时支持多个代码页。只要文件能说明自己使 用什么编码，用户又安装了对应的代码页，Windows就能正确显示，例如在HTML文件中就可 以指定char set。
有的HTML文件作者，特别是英文作者，认为世界上所有人都使用英文，在文件中不指定char set。如果他使用了0x80-0xff之间的字符，中文Windows又按照缺省的GBK去解释，就会 出现乱码。这时只要在这个html文件中加上指定char set的语句，例如：如果原作者使用的 代码页和ISO8859-1兼容，就不会出现乱码了。
再说区位码，啊的区位码是1601，写成16进制是0x10,0x01。这和计算机广泛使用的ASCII 编码冲突。为了兼容00-7f的 ASCII编码，我们在区位码的高、低字节上分别加上A0。这样 “啊”的编码就成为B0A1。我们将加过两个A0的编码也称为GB2312编码，虽然 GB2312的原文根本没提到这一点。

[source](https://www.cnblogs.com/finallyliuyu/archive/2013/05/10/3071023.html)

### 怎么转？

那么 ，怎么转？这种转换多发生在windows系统上；答案就是换代码页；

- WideCharToMultiByte 将UTF-16（宽字符）字符串映射到新字符串。新字符串不一定来自多字节字符集。

- MultiByteToWideChar 将字符串映射到UTF-16（宽字符）字符串。字符串不一定来自多字节字符集。

代码页指代参数：

**CP_ACP**  The system default **Windows ANSI** code page.

> **Note**  This value can be different on different computers, even on the same network. It can be changed on the same computer, leading to stored data becoming irrecoverably corrupted. This value is only intended for temporary use and permanent storage should use UTF-16 or UTF-8 if possible.

**CP_UTF8**  UTF-8

可见，在windows的所谓转换其实只是做了一个编码标准的重新映射而已。所以，当我们在做编码转换前，我们一定要先确认我们的内存中的二进制是不是我们认为的编码标准，如果不是，转出来的就是肉眼可视的乱码。



## big endian和little endian 

big endian和little endian是CPU处理多字节数的不同方式。例如“汉”字的Unicode编码是6C49。那么写到文件里时，究竟是将6C写在前面，还是将49写在前面？如果将6C写在前面，就是big endian。还是将49写在前面，就是little endian。 

UTF-8以字节为编码单元，没有字节序的问题。UTF-16以两个字节为编码单元，在解释一个 UTF-16文本前，首先要弄清楚每个编码单元的字节序。例如“奎”的Unicode编码是594E， “乙”的Unicode编码是4E59。如果我们收到UTF-16字节流“594E”，那么这是“奎” 还 是“乙”？
Unicode规范中推荐的标记字节顺序的方法是BOM。BOM不是“Bill Of Material”的BOM表 ，而是Byte Order Mark。BOM是一个有点小聪明的想法：
在UCS编码中有一个叫做"ZERO WIDTH NO-BREAK SPACE"的字符，它的编码是FEFF。而FFFE 在UCS中是不存在的字符，所以不应该出现在实际传输中。UCS规范建议我们在传输字节流 前，先传输字符"ZERO WIDTH NO-BREAK SPACE"。
这样如果接收者收到FEFF，就表明这个字节流是Big-Endian的；如果收到FFFE，就表明这 个字节流是Little-Endian的。因此字符"ZERO WIDTH NO-BREAK SPACE"又被称作BOM。
UTF-8不需要BOM来表明字节顺序，但可以用BOM来表明编码方式。字符"ZERO WIDTH NO-BR EAK SPACE"的UTF-8编码是EF BB BF（读者可以用我们前面介绍的编码方法验证一下）。所 以如果接收者收到以EF BB BF开头的字节流，就知道这是UTF-8编码了。
Windows就是使用BOM来标记文本文件的编码方式的。