# 编码到底是个啥

> 这里的编码不是指编写代码，而是字符的编码方式；

先提出几个问题：

1. utf8 和 unincode 是一回事么？
2. ANSI 编码和 ASCII 码是什么
3. 宽字节 和窄字节又是什么
4. 国标码和 utf8 有什么不同？
5. wchar_t 和 char

首先 明确一点，计算机只认识 0 和 1，所以计算机不管是存还是读取都是基于 0 和 1 的序列；
而把这些 0 和 1 组成的序列组织起来变成人类可读的文字就是**编码标准**需要完成的工作了。

打开 sublime 的 encoding 列表，我们可以看到编码标准是真的多，每个地区和国家似乎都想把 0 和 1 的序列定义一下然后组成自己国家的文字，可以，这带来了很大的麻烦。特别是在全球互联的背景下。因为 A 国的 01 序列组成的 A 国标准的文字编码到了 B 国会按 B 国的文字编码重新解读，于是在 B 国人们的解读下，就是一团乱码，形成了`我的编码你不懂`的状况。

## Unicode

于是 Unicode 出来了，被称为世界级的标准字符集，里面拟定了所有国家所有地区的文字的全集。不论英语、中文、俄语还是什么不知名的语种，unicode 无所不包。那么你可能会问，字符集又是什么呢？还是回到计算机的原理说起，计算机只认识 0 和 1 ，人们自然也只能使用 0 和 1 组成的序列来组成字符集了，于是在 unicode 里，比如说 41 标示 A。可以这么说，人们把数字从 0 往后数，每个数字都标示一个字。因为英语的特殊地位，它自然在数数的最前头。

所以，**我认为所谓字符集就是定义了数字和字的映射关系**；不够 unicode 做的大，把世界上所有的文字都映射进去了；

## UTF-8 和 UTF-16

UTF 是 A Unicode transformation format 的简写；

使用 Unicode 的数字和字的映射关系的编码方式 主要是 UTF-8 和 UTF-16；
现在回头看看 UTF-8，现在我们就需要把这些数在计算机里表示出来了，可以说 UTF-8 是最折中的表示方案，它先使用 8 位 bit 表示一个数字，比如 1，2，3 的表示方式为`0000 0001` `0000 0010` `0000 0011`,值得注意的是，这里的 1 2 3 并不是真实的我们语言世界里的 1 2 3 ，而需要查询[Unicode 映射表](https://unicode-table.com/en/#0001)后知道数字 1 对应的值 为 SOH ,2 对应 STX ，3 对应 ETX；

不过，我们知道，8 位的 2 进制数最大只能到 255，大于 255 的数字怎么表示呢？再往 8 位里面加 8 位序列，扩容，也就是变成了 16 位表示一个更大的数；事实上 utf-8 编码 到了 007F 后即开始使用 16 位表示更大的数了；
而更大的数字则使用更多的数位表示，目前最大到了 32 位；具体的编码方式 [参看这里](https://naveenr.net/unicode-character-set-and-utf-8-utf-16-utf-32-encoding/)

UTF-16 同 UTF-8 理解一样，使用 16 位表示最初的数字，UTF-16 编码是一种可变字节编码方案，它使用 2 个字节或 4 个字节来表示 unicode 代码点。 所有现代语言的大多数字符都使用 2 个字节表示。如 1 的表示为 `00000000 0000 0001`仍然表示 Unicode 里的 SOH。不能把 UTF-16 理解为一个 16 位的编码方式；

同理的：UTF-32 编码是固定字节编码方案，它使用 4 个字节来表示所有代码点。

现在我们来回答 第一个问题：
unicode 是一个字符集标准，它规定了数字和具体的字之间的映射关系；
而 UTF-家族是 unicode 里的数字（代码点）的编码实现方式；

## ANSI 编码

American National Standards Institute （美国国家标准协会）

ANSI 编码是一个稍微通用的术语，用于指代系统上的标准代码页，通常是 Windows。 在西方/美国，它被更恰当地称为 Windows-1252.系统。 （它可以代表其他系统上的某些其他 Windows 代码页。）这实际上是 ASCII 字符集的扩展，因为它包含所有带有 128 个字符代码的 ASCII 字符。 这种差异是由于“ANSI”编码是 8 位而不是 7 位，因为 ASCII 是（ASCII 现在几乎总是编码为 8 位字节，MSB 设置为 0）。 名称“ANSI”用词不当，因为它不符合任何实际的 ANSI 标准，但名称已卡住。 ANSI 与 UTF-8 不同。

严格来说，没有 ANSI 编码这样的东西。 通俗地，术语 ANSI 用于几种不同的编码：`ISO 8859-1` `Windows CP1252` Windows 机器上的当前系统编码（在 Win32 API 术语中）。

维基百科的定义：
`
ANSI character set
From Wikipedia, the free encyclopedia
Jump to navigationJump to search
The phrase ANSI character set has no well-defined meaning and has been used to refer to the following, among other things:

Windows code pages, a collection of 8-bit character sets compatible with ASCII but incompatible with each other, especially those code pages that are partly compatible with ISO-8859, most commonly Windows Latin 1
Windows-1252 is referred to as "ANSI" especially often.
Code page 437, the character set of the original IBM PC (especially in the context of ANSI art which is used as graphics especially in BBS and made as demoscene products.)
ASCII, a 7-bit character set. (Very rarely.)
ANSEL, the American National Standard for Extended Latin Alphabet Coded Character Set. (Very rarely.)
ISO-8859, a collection of 8-bit character sets compatible with ASCII. (Very rarely.)

ANSI 字符集没有明确定义的含义，并且用于指代以下内容：
Windows 代码页，
8 位字符的集合 与 ASCII 兼容但彼此不兼容的集合，
尤其是那些与 ISO-8859 部分兼容的代码页，最常见的是 Windows Latin 1
Windows-1252 特别经常被称为“ANSI”。 代码页 437，
原始 IBM PC 的字符集（特别是在 ANSI 艺术的上下文中，特别是在 BBS 中用作图形并作为 demoscene 产品。）
ASCII，一个 7 位字符集。 （非常罕见。）
ANSEL，扩展拉丁字母编码字符集的美国国家标准。 （非常罕见。）
ISO-8859，与 ASCII 兼容的 8 位字符集的集合。 （非常稀有。）
`

## ASCII 码

ASCII 只定义了一个带有 128 个符号的 7 位代码页

回答第二个问题，在 windows 系统中，使用 ANSI 编码概念完全是个误会，是指代 windows 的代码页，所以我们经常使用不同的代码页转换来却换字符编码，而 ascii 是一个只包含少量符号和英文的字符集，由 7 位 bit 表示；

## 宽字节 和窄字节

在 win32 开发中一个项目的字符集一般分为 Unicode 字符集和多字节字符集，一般我们会选择 Unicode 字符集，因为这样很方便我们开发，值得一提的是，Unicode 字符集也许我们很熟悉，平时所说的宽字节就是 Unicode，多字节就是指的 ANSI，GB 等。

这些从 ANSI 标准派生的字符集被习惯的统称为 ANSI 字符集，这样的字符集有很多，我们常见的 GB-2312 就是其中之一。它们正式的名称应该是 MBCS(Multi-Byte Chactacter System，即多字节字符系统)。这些派生字符集的特点是以 ASCII 127 bits 为基础，兼容 ASCII 127，他们使用大于 128 的编码作为一个 Leading Byte，紧跟在 Leading Byte 后的第二（甚至第三）个字符与 Leading Byte 一起作为实际的编码。

所以，可知，我们常说的宽字节 实际就是指的使用 unicode 编码方式
而窄字节 是 MBCS 系列的编码方式；

### char

我们使用 char 表示一个窄字节符号；那么问题来了，当我们使用 char 存储中文时，发生了什么呢？
看下代码就明白了

```c++
#include <iostream>
#include <cstring>
int main(int argc, char const *argv[]) {

    char chinese[] = "中文";
    std::cout << "size of 中文 is:" << sizeof(chinese) << std::endl;
    std::cout << "length of 中文 is:" << strlen(chinese) << std::endl;

    char english[] = "eg";
    std::cout << "size of eg is:" << sizeof(english) << std::endl;
    std::cout << "length of eg is:" << strlen(english) << std::endl;

    wchar_t Lchinese[] = L"中文";
    std::wcout << "size of L中文 is:" << sizeof(Lchinese) << std::endl;
    std::wcout << "length of L中文 is:" << wcslen(Lchinese) << std::endl;
    wchar_t Lenglish[] = L"eg";
    std::wcout << "size of Leg is:" << sizeof(Lenglish) << std::endl;
    std::wcout << "length of Leg is:" << wcslen(Lenglish) << std::endl;
    return 0;
}
```

输出结果

```c++
size of 中文 is:7
length of 中文 is:6
size of eg is:3
length of eg is:2
size of L is:12
length of L is:2
size of Leg is:12
length of Leg is:2
[Finished in 1.0s]
```

这段程序是在 linux 系统的输出结果，暂时没有 windows 的环境；
先说说 char，在 linux 下，一个 char 是 1 个字节，我的编程文件是 utf-8 格式的，所以每个中文都是使用 utf-8 存储，我们查看“中的”utf-8 编码是`0xE4 0xB8 0xAD`,而“文”的是`0xE6 0x96 0x87`。可见“中文”二字需要 6 个字节 来安放自己，加上`\0`，一共 7 个字节。
而计算 length 时，是按 char 来分割计算的，一个 6 个 char。

英文就好理解了，e 和 g 各占一个 char，不需要 多余的解释了。

当使用 whar_t 时，linux 系统使用 UTF-32 来表示，即每个字符都是 4 位字节的，“中”的 UTF-32 的编码为`0x00004E2D`， “文”为`0x00006587` ，所以二者一共 8 个字节，另外需要注意的是结束符也是占用 4 个字节的，所以它们一起需要的字节数就是 12 了。
不过，在 length 上，还是 2 个 wchar_t。

由此，我们得出的结论是，char 和 wchar_t 都可以存储中文；而当我们使用 char 存储中文时，是比 wchar_t 使用的空间要小的，但是我们在计算字符串长度时是不准确的。所以，这里，我认为，当我们需要使用一段非西文字符串具体长度的时候，一定要使用 wchar_t 来存储，这其实是一个粒度问题。

### wchar_t

在实际开发中，我们使用 wchar_t 表示一个宽字节符号：
While a char takes up a single byte, a **wchar_t** takes up 4 bytes on **Linux** in contrast to the 2 bytes that **wchar_t** takes up in **Windows** NT.

在 linux 里，一个宽字节 wchar_t 占用 4 个字节，而在 windows 里占用 2 个字节，二者说到底是使用的 unicode 的编码方式不同，llnux 里使用 UTF-32 ，而 windows 里使用 UTF-16。

继续上面的例子，之前的代码文件的编码是 utf-8 的，那么如果我把它改为 gb2312 呢，会发生什么？

在我的 linux 系统下，无法编译通过，因为 linux 系统无法解读 gb2312 编码，所以无法通过；
还是看看 windows 系统吧，在中文操作系统下，VS 的默认编码就是 gb2312 的。
运行结果为

```c++
size of 中文 is:5
length of 中文 is:4
size of eg is:3
length of eg is:2
size of L中文 is:6
length of L中文 is:2
size of Leg is:6
length of Leg is:2
```

先说 char 时的，**中**的 GB2312 编码为`D6D0`,占用两个字节 ；**文**的为`CEC4`。二者一共 4 个字节，加一个结束符，共 5 个字节的 size；而 length 是 4 个 char；使用的[在线查询工具](https://www.qqxiuzi.cn/bianma/zifuji.php)

在 wchar_t 时，windows 使用 UTF-16 编码，**中**为`\4e\2d` ，**文**为`\65\87`，二者一共 4 个字节。
再加 2 个字节的结束符，一共 6 个字节的 size；而 length 是 2 个 wchar_t。

由此可见，使用不同的编码方式，对编程的影响是巨大的，而只有统一了字符的类型，才能跨平台使用，而不至于因编码问题把代码改来改去。

## GB2312

简体中文的国标码，不过后者是包括了前者的。在 windows 下编程，一定会和这个编码方式打交道。

之后 ，有发展出了 GBK ，后续的扩大集合为 GB18030。

具体的[参看这里](https://www.zhihu.com/question/19677619)

可以简单的区分为 GB 2312 过时标准、GBK 微软标准、GB 18030 国家标准三个标准
一般情况用 GB18030 即可，方正都是向下兼容的.

## 字符编码的转换

### 为什么要转

我们先看看如下代码的输出

```c++
#include <iostream>
#include <cstring>

int main(int argc, char const *argv[]) {
    char chinese[] = "中文";
    unsigned int c1 = chinese[0];
    std::cout << "chinese char1 0x" << std::hex << c1 << "\n";

    wchar_t Lchinese[] = L"中文";
    unsigned int c2 = Lchinese[0];
    std::cout << "Lchinese char1 0x" << std::hex << c2 << "\n";
    return 0;
}
```

Linux 下：

```cpp
chinese char1 0xffffffe4
Lchinese char1 0x4e2d
```

windows 下

```cpp
chinese char1 0xffffffd6
Lchinese char1 0x4e2d
```

解释：

Linux 下使用的 utf-8 文件编码，编译期并不识别 gb2312，所以第一个字符 char 中存储的是汉字`中`的第一个 UTF8 编码，入前所述为 e4

windows 下使用的是国标码，GB2312，汉字中的第一个 GB 码数字为 D6 ,符合查询结果。

两个系统上，使用 L 封装的字符，在内存中二进制形式是一样的，都是`4e2d`，

可见，在两种编码的文件下，文字本身虽然`中文`两字，但是实际的存储方式其实是不同的。那么反向思考下，对于存储的二进制的磁盘而言，我们需要招对合适的解码方式才能正常显示汉字，否则，将出现乱码，乱码的根本原因就是把本属于编码标准的二进制序列使用了其他的编码方式去映射。如果乱码后要显示成可识别的字，那么就需要编码转换了，不过弄明白了乱码的本质，要使得回复本来面目也就清楚了，即让**错误的编码映射解读为正确的映射关系**即可。

目前 Windows 的内核已经采用 Unicode 编码，这样在内核上可以支持全世界所有的语言文字 。但是由于现有的大量程序和文档都采用了某种特定语言的编码，例如 GBK，Windows 不可 能不支持现有的编码，而全部改用 Unicode。
Windows 使用代码页(code page)来适应各个国家和地区。code page 可以被理解为前面提到 的内码。GBK 对应的 code page 是 CP936。
微软也为 GB18030 定义了 code page：CP54936。但是由于 GB18030 有一部分 4 字节编码，而 Windows 的代码页只支持单字节和双字节编码，所以这个 code page 是无法真正使用的。

所谓代码页(code page)就是针对一种语言文字的字符编码。

例如 GBK 的 code page 是 CP936 ，

BIG5 的 code page 是 CP950，

GB2312 的 code page 是 CP20936。

Windows 中有缺省代码页的概念，即缺省用什么编码来解释字符。例如 Windows 的记事本打 开了一个文本文件，里面的内容是字节流：BA、BA、D7、D6。Windows 应该去怎么解释它呢 ？
是按照 Unicode 编码解释、还是按照 GBK 解释、还是按照 BIG5 解释，还是按照 ISO8859-1 去解 释？如果按 GBK 去解释，就会得到“汉字”两个字。按照其它编码解释，可能找不到对应的 字符，也可能找到错误的字符。所谓“错误”是指与文本作者的本意不符，这时就产生了 乱码。
答案是 Windows 按照当前的**缺省代码页**去解释文本文件里的字节流。缺省代码页可以通过控 制面板的区域选项设置。记事本的另存为中**有一项 ANSI，其实就是按照缺省代码页的编码 方法保存**。

Windows 的内码是 Unicode，它在技术上可以同时支持多个代码页。只要文件能说明自己使 用什么编码，用户又安装了对应的代码页，Windows 就能正确显示，例如在 HTML 文件中就可 以指定 char set。
有的 HTML 文件作者，特别是英文作者，认为世界上所有人都使用英文，在文件中不指定 char set。如果他使用了 0x80-0xff 之间的字符，中文 Windows 又按照缺省的 GBK 去解释，就会 出现乱码。这时只要在这个 html 文件中加上指定 char set 的语句，例如：如果原作者使用的 代码页和 ISO8859-1 兼容，就不会出现乱码了。
再说区位码，啊的区位码是 1601，写成 16 进制是 0x10,0x01。这和计算机广泛使用的 ASCII 编码冲突。为了兼容 00-7f 的 ASCII 编码，我们在区位码的高、低字节上分别加上 A0。这样 “啊”的编码就成为 B0A1。我们将加过两个 A0 的编码也称为 GB2312 编码，虽然 GB2312 的原文根本没提到这一点。

[source](https://www.cnblogs.com/finallyliuyu/archive/2013/05/10/3071023.html)

### 怎么转

那么 ，怎么转？这种转换多发生在 windows 系统上；答案就是换代码页；

- WideCharToMultiByte 将 UTF-16（宽字符）字符串映射到新字符串。新字符串不一定来自多字节字符集。

- MultiByteToWideChar 将字符串映射到 UTF-16（宽字符）字符串。字符串不一定来自多字节字符集。

代码页指代参数：

**CP_ACP** The system default **Windows ANSI** code page.

> **Note** This value can be different on different computers, even on the same network. It can be changed on the same computer, leading to stored data becoming irrecoverably corrupted. This value is only intended for temporary use and permanent storage should use UTF-16 or UTF-8 if possible.

**CP_UTF8** UTF-8

可见，在 windows 的所谓转换其实只是做了一个编码标准的重新映射而已。所以，当我们在做编码转换前，我们一定要先确认我们的内存中的二进制是不是我们认为的编码标准，如果不是，转出来的就是肉眼可视的乱码。

## big endian 和 little endian

big endian 和 little endian 是 CPU 处理多字节数的不同方式。例如“汉”字的 Unicode 编码是 6C49。那么写到文件里时，究竟是将 6C 写在前面，还是将 49 写在前面？如果将 6C 写在前面，就是 big endian。还是将 49 写在前面，就是 little endian。

UTF-8 以字节为编码单元，没有字节序的问题。UTF-16 以两个字节为编码单元，在解释一个 UTF-16 文本前，首先要弄清楚每个编码单元的字节序。例如“奎”的 Unicode 编码是 594E， “乙”的 Unicode 编码是 4E59。如果我们收到 UTF-16 字节流“594E”，那么这是“奎” 还 是“乙”？
Unicode 规范中推荐的标记字节顺序的方法是 BOM。BOM 不是“Bill Of Material”的 BOM 表 ，而是 Byte Order Mark。BOM 是一个有点小聪明的想法：
在 UCS 编码中有一个叫做"ZERO WIDTH NO-BREAK SPACE"的字符，它的编码是 FEFF。而 FFFE 在 UCS 中是不存在的字符，所以不应该出现在实际传输中。UCS 规范建议我们在传输字节流 前，先传输字符"ZERO WIDTH NO-BREAK SPACE"。
这样如果接收者收到 FEFF，就表明这个字节流是 Big-Endian 的；如果收到 FFFE，就表明这 个字节流是 Little-Endian 的。因此字符"ZERO WIDTH NO-BREAK SPACE"又被称作 BOM。
UTF-8 不需要 BOM 来表明字节顺序，但可以用 BOM 来表明编码方式。字符"ZERO WIDTH NO-BR EAK SPACE"的 UTF-8 编码是 EF BB BF（读者可以用我们前面介绍的编码方法验证一下）。所 以如果接收者收到以 EF BB BF 开头的字节流，就知道这是 UTF-8 编码了。
Windows 就是使用 BOM 来标记文本文件的编码方式的。
